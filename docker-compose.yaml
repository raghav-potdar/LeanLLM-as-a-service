services:
  model-downloader:
    image: alpine:3.20
    command:
      - /bin/sh
      - -c
      - |
        set -e
        apk add --no-cache wget
        if [ ! -f /models/Llama-3.2-1B-Instruct-Q4_K_M.gguf ]; then
          echo "Downloading model..."
          wget -O /models/Llama-3.2-1B-Instruct-Q4_K_M.gguf \
            "https://huggingface.co/medmekk/Llama-3.2-1B-Instruct.GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf"
        else
          echo "Model already present, skipping download."
        fi
    volumes:
      - ./models:/models
    networks:
      - llmnet
    restart: "no"

  llama:
    image: ghcr.io/ggml-org/llama.cpp:server
    depends_on:
      model-downloader:
        condition: service_completed_successfully
    command:
      - --model
      - /models/Llama-3.2-1B-Instruct-Q4_K_M.gguf
      - --host
      - 0.0.0.0
      - --port
      - "8000"
      - --ctx-size
      - "4096"
      - --parallel
      - "1"
      - --threads
      - "2"
      - --metrics
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -qO- http://localhost:8000/metrics >/dev/null 2>&1 || curl -fsS http://localhost:8000/metrics >/dev/null"
        ]
      interval: 30s
      timeout: 5s
      retries: 5
    volumes:
      - ./models:/models:ro
    expose:
      - "8000"
    networks:
      - llmnet
    restart: unless-stopped

  nginx:
    image: nginx:1.27-alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/logs:/var/log/nginx
      - ./nginx/static:/usr/share/nginx/html:ro
    depends_on:
      - llama
    networks:
      - llmnet
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -qO- http://localhost/health >/dev/null 2>&1 || curl -fsS http://localhost/health >/dev/null"
        ]
      interval: 30s
      timeout: 5s
      retries: 5

  prometheus:
    image: prom/prometheus:v2.54.1
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
    depends_on:
      - llama
      - node-exporter
      - alertmanager
      - nginxlog-exporter
    networks:
      - llmnet
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -qO- http://localhost:9090/-/healthy >/dev/null 2>&1 || curl -fsS http://localhost:9090/-/healthy >/dev/null"
        ]
      interval: 30s
      timeout: 5s
      retries: 5

  grafana:
    image: grafana/grafana:11.1.4
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    networks:
      - llmnet
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -qO- http://localhost:3000/api/health >/dev/null 2>&1 || curl -fsS http://localhost:3000/api/health >/dev/null"
        ]
      interval: 30s
      timeout: 5s
      retries: 10

  alertmanager:
    image: prom/alertmanager:v0.27.0
    ports:
      - "9093:9093"
    volumes:
      - ./prometheus/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    networks:
      - llmnet
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -qO- http://localhost:9093/-/healthy >/dev/null 2>&1 || curl -fsS http://localhost:9093/-/healthy >/dev/null"
        ]
      interval: 30s
      timeout: 5s
      retries: 5

  node-exporter:
    image: prom/node-exporter:v1.8.2
    command:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/rootfs
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    expose:
      - "9100"
    networks:
      - llmnet
    restart: unless-stopped

  nginxlog-exporter:
    image: quay.io/martinhelmich/prometheus-nginxlog-exporter:latest
    command:
      - -config-file
      - /etc/nginxlog-exporter.yml
    volumes:
      - ./nginx/nginxlog-exporter.yml:/etc/nginxlog-exporter.yml:ro
      - ./nginx/logs:/var/log/nginx:ro
    depends_on:
      - nginx
    expose:
      - "4040"
    networks:
      - llmnet
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -qO- http://localhost:4040/metrics >/dev/null 2>&1 || curl -fsS http://localhost:4040/metrics >/dev/null"
        ]
      interval: 30s
      timeout: 5s
      retries: 5

networks:
  llmnet:
    driver: bridge

